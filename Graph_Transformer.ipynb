{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/albertomariapepe/Using-a-Graph-Transformer-network-to-predict-3D-coordinates-of-proteins-via-Geometric-Algebra-model/blob/main/Graph_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6zsVRdBT3mL"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMhZj0ZUNJck"
      },
      "outputs": [],
      "source": [
        "! wget http://deep.cs.umsl.edu/pdnet/train-data.tar.gz\n",
        "! tar zxf train-data.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x93wrLcoZ7bq"
      },
      "outputs": [],
      "source": [
        "!pip install graph-transformer-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-msssim"
      ],
      "metadata": {
        "id": "mltpyJyADLXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTmqVTqGKOpJ"
      },
      "outputs": [],
      "source": [
        "!pip install pycuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_gTMkOMvhBt"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCSZGfYYNMUM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "import numpy as np\n",
        "import random\n",
        "from pytorch_msssim import SSIM\n",
        "import gc\n",
        "from graph_transformer_pytorch import GraphTransformer\n",
        "import time\n",
        "from google.colab import files\n",
        "import pycuda.driver as cuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sxzht4ePoM1"
      },
      "outputs": [],
      "source": [
        "def get_nodes_and_edges(pdb, all_feat_paths, node_n, edge_n):\n",
        "    features = None\n",
        "    for path in all_feat_paths:\n",
        "        if os.path.exists(path + pdb + '.pkl'):\n",
        "            features = pickle.load(open(path + pdb + '.pkl', 'rb'))\n",
        "    l = len(features['seq'])\n",
        "    seq = features['seq']\n",
        "\n",
        "    nodes = torch.zeros(1, l, node_n)\n",
        "    edges = torch.zeros(1, l, l, edge_n) \n",
        "    mask = torch.ones(1, l).bool()\n",
        "\n",
        "    ######NODES FEATURES########\n",
        "\n",
        "    # Add secondary structure\n",
        "    ss = features['ss']\n",
        "    assert ss.shape == (3, l)\n",
        "    fi = 0\n",
        "    gi = 0\n",
        "\n",
        "    for j in range(3):\n",
        "        a = np.repeat(ss[j].reshape(1, l), l, axis = 0)\n",
        "        a = a[0,0:l]\n",
        "        np.reshape(a, [1, l])\n",
        "        nodes[:, :, fi] = torch.from_numpy(a).to(nodes)\n",
        "        fi += 1\n",
        "    # Add PSSM\n",
        "    pssm = features['pssm']\n",
        "    assert pssm.shape == (l, 22)\n",
        "    for j in range(22):\n",
        "        a = np.repeat(pssm[:, j].reshape(1, l), l, axis = 0)\n",
        "        a = a[0,0:l]\n",
        "        np.reshape(a, [1, l])\n",
        "        nodes[:, :, fi] = torch.from_numpy(a).to(nodes)\n",
        "        fi += 1\n",
        "\n",
        "    # Add SA\n",
        "    sa = features['sa']\n",
        "    assert sa.shape == (l, )\n",
        "    a = np.repeat(sa.reshape(1, l), l, axis = 0)\n",
        "    a = a[0,0:l]\n",
        "    np.reshape(a, [1, l])\n",
        "    nodes[:, :, fi] = torch.from_numpy(a).to(nodes)\n",
        "    fi += 1\n",
        "\n",
        "    # Add entropy\n",
        "    entropy = features['entropy']\n",
        "    assert entropy.shape == (l, )\n",
        "    a = np.repeat(entropy.reshape(1, l), l, axis = 0)\n",
        "    a = a[0,0:l]\n",
        "    np.reshape(a, [1, l])\n",
        "    nodes[:, :, fi] = torch.from_numpy(a).to(nodes)\n",
        "    fi += 1\n",
        "\n",
        "    ######EDGES FEATURES########\n",
        "\n",
        "    # Add CCMpred\n",
        "    ccmpred = features['ccmpred']\n",
        "    assert ccmpred.shape == ((l, l))\n",
        "    edges[:, :, :, gi] = torch.from_numpy(ccmpred).to(edges)\n",
        "    gi += 1\n",
        "    # Add  FreeContact\n",
        "    freecon = features['freecon']\n",
        "    assert freecon.shape == ((l, l))\n",
        "    edges[:, :, :, gi] = torch.from_numpy(freecon).to(edges)\n",
        "    gi += 1\n",
        "    # Add potential\n",
        "    potential = features['potential']\n",
        "    assert potential.shape == ((l, l))\n",
        "    edges[:, :, :, gi] = torch.from_numpy(potential).to(edges)\n",
        "    gi += 1\n",
        "    \n",
        "    \n",
        "    #cost = np.load('drive/MyDrive/Output-ALL/'+ pdb + '-cb.npy', allow_pickle = True)\n",
        "    cost = np.load('drive/MyDrive/COSTS-predicted-realdistance/'+ pdb + '-cb.npy', allow_pickle = True)\n",
        "\n",
        "    edges[:, :, :, gi] = torch.from_numpy(cost[2]).to(edges)\n",
        "    gi += 1 \n",
        "    \n",
        "    \n",
        "    #distance = np.load('drive/MyDrive/DISTANCES/'+ pdb + '-cb.npy', allow_pickle = True)\n",
        "    distance = np.load('drive/MyDrive/DISTANCES-predicted/'+ pdb + '-cb.npy', allow_pickle = True)\n",
        "    edges[:, :, :, gi] = torch.from_numpy(distance[2]).to(edges)\n",
        "\n",
        "    return nodes, edges, mask, l\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjE7kiDA3e87"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(Net, self).__init__()\n",
        "      self.fc1 = nn.Linear(27,3, bias = False)\n",
        "\n",
        "    def forward(self, x, old):\n",
        "      output = self.fc1(x)\n",
        "      return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgVdLZqS67vJ"
      },
      "outputs": [],
      "source": [
        "node_n = 27\n",
        "edge_n = 5\n",
        "\n",
        "GT = GraphTransformer(\n",
        "    dim = node_n,\n",
        "    depth = 3,\n",
        "    heads = 4,\n",
        "    edge_dim = edge_n,             # optional - if left out, edge dimensions is assumed to be the same as the node dimensions above\n",
        "    with_feedforwards = True,   # whether to add a feedforward after each attention layer, suggested by literature to be needed\n",
        "    gated_residual = True,      # to use the gated residual to prevent over-smoothing\n",
        "    rel_pos_emb = True          # set to True if the nodes are ordered, default to False\n",
        ")\n",
        "\n",
        "projector3D = Net()\n",
        "\n",
        "GT.cuda()\n",
        "projector3D.cuda()\n",
        "model = nn.Sequential(GT, projector3D)\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9K57DVQWam80"
      },
      "outputs": [],
      "source": [
        "dir = '/content/drive/MyDrive/DISTANCES/'\n",
        "lst = os.listdir(dir)\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "cuda.init()\n",
        "dir_dataset = './data/'\n",
        "all_feat_paths = [dir_dataset + '/deepcov/features/', dir_dataset + '/psicov/features/', dir_dataset + '/cameo/features/']\n",
        "all_dist_paths = [dir_dataset + '/deepcov/distance/', dir_dataset + '/psicov/distance/', dir_dataset + '/cameo/distance/']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if os.path.isfile('/content/model.pt'):\n",
        "    print('loading model...')\n",
        "    model.load_state_dict(torch.load(\"/content/model.pt\"))\n",
        "    \n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
        "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9, verbose = True)\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "lsttrain = lst[0:200]\n",
        "lstval = lst[1000:1200]\n",
        "\n",
        "epochs = 5\n",
        "n_batches = int(len(lsttrain))\n",
        "batch_size = len(lsttrain) // n_batches\n",
        "#batch_size = 1\n",
        "\n",
        "L = nn.L1Loss()\n",
        "ssim_module = SSIM(data_range=255, size_average=True, channel=1)\n",
        "counter = 0\n",
        "loss = 0\n",
        "j_in = 0\n",
        "i_in = 0\n",
        "alpha = 20\n",
        "\n",
        "edge_len = 4 #it is 4 when we include cost maps\n",
        "for i in range(i_in, epochs): \n",
        "        #torch.cuda.empty_cache()\n",
        "        #gc.collect()\n",
        "        #torch.no_grad()\n",
        "\n",
        "        lstbatch = []\n",
        "        #random.shuffle(lsttrain)\n",
        "        filename1 = random.choice(lstval)\n",
        "        print('****')\n",
        "        \n",
        "        if i == 0:\n",
        "          j_in = 0\n",
        "        \n",
        "        else:\n",
        "          j_in = 0\n",
        "        \n",
        "        for j in range(j_in, n_batches):\n",
        "            #torch.cuda.empty_cache()\n",
        "            #gc.collect()\n",
        "            #torch.no_grad()\n",
        "\n",
        "            lstbatch = lsttrain[j*batch_size:(j+1)*batch_size]\n",
        "            \n",
        "    \n",
        "            loss = 0\n",
        "            val_loss = 0\n",
        "            counter = 0\n",
        "\n",
        "            #print(lstbatch)\n",
        "            #print(len(lstbatch))\n",
        "            #print(lstbatch)\n",
        "\n",
        "            for filename in lstbatch:\n",
        "                \n",
        "                filename = os.path.splitext(filename)[0]\n",
        "                filename = filename[:-3]\n",
        "                #print(filename)\n",
        "                loss1 = 0\n",
        "                loss2 = 0\n",
        "                \n",
        "                \n",
        "                nodes, edges, mask, l = get_nodes_and_edges(filename, all_feat_paths, node_n, edge_n)\n",
        "                #print(\"TIME TO EXTRACT: \", time.time() - start)\n",
        "                \n",
        "                nodes = nodes.cuda()\n",
        "                edges = edges.cuda()\n",
        "                mask = mask.cuda()\n",
        "               \n",
        "              \n",
        "                nodes_new, edges_new = GT(nodes, edges, mask = mask)\n",
        "                \n",
        "                nodes_new = nodes_new.cuda()\n",
        "                edges_new = edges_new.cuda()\n",
        "                \n",
        "                coord = projector3D(nodes_new, nodes)\n",
        "                \n",
        "                #noise = np.random.normal(0,1,[coord.shape[1], 3])\n",
        "                #coord = coord + torch.from_numpy(noise).cuda()\n",
        "\n",
        "\n",
        "                coord.cuda()\n",
        "                \n",
        "\n",
        "                Y = edges[:,:,:,edge_len]\n",
        "\n",
        "                X = torch.zeros(coord.shape[1], coord.shape[1]) \n",
        "                pred_dist = torch.zeros(1, coord.shape[1], coord.shape[1]) \n",
        "\n",
        "                Y.cuda()\n",
        "                X.cuda()\n",
        "\n",
        "                pred_dist.cuda()\n",
        "\n",
        "                start = time.time()\n",
        "                for p in range (0,int(coord.shape[1])):\n",
        "                    for q in range (0, p):\n",
        "                        X[p,q] = torch.linalg.norm(coord[0,p,:] -  coord[0,q,:])\n",
        "\n",
        "               \n",
        "                pred_dist[0] = X + X.T - torch.diag(X)\n",
        "                #print(\"ELAPSED TIME to EVALUATE PRED MAP: \", time.time() - start)\n",
        "\n",
        "                #print(X)\n",
        "\n",
        "\n",
        "                pred_dist = pred_dist.cuda()\n",
        "\n",
        "\n",
        "                loss1 = L(pred_dist, Y)\n",
        "                loss2 = 1 - ssim_module(pred_dist.unsqueeze(0), Y.unsqueeze(0))\n",
        "                loss = loss1 + alpha*loss2\n",
        "                counter = counter + 1\n",
        "                \n",
        "                \n",
        "\n",
        "                del nodes, edges, nodes_new, edges_new, mask, coord, X, Y, pred_dist\n",
        "                torch.cuda.empty_cache()\n",
        "                gc.collect()\n",
        "                torch.no_grad()\n",
        "\n",
        "                ####################################Validation\n",
        "                \n",
        "                filename = filename1\n",
        "\n",
        "                filename = os.path.splitext(filename)[0]\n",
        "                filename = filename[:-3]\n",
        "      \n",
        "\n",
        "                nodes, edges, mask, l = get_nodes_and_edges(filename, all_feat_paths, node_n, edge_n)\n",
        "\n",
        "                nodes = nodes.cuda()\n",
        "                edges = edges.cuda()\n",
        "                mask = mask.cuda()\n",
        "\n",
        "                nodes_new, edges_new = GT(nodes, edges, mask = mask)\n",
        "                \n",
        "                nodes_new = nodes_new.cuda()\n",
        "                edges_new = edges_new.cuda()\n",
        "\n",
        "                coord = projector3D(nodes_new, nodes)\n",
        "                coord.cuda()\n",
        "\n",
        "              \n",
        "                Y = edges[:,:,:,edge_len]\n",
        "\n",
        "\n",
        "                #lstval.remove(filename+'-cb.npy')\n",
        "\n",
        "                X = torch.zeros(coord.shape[1], coord.shape[1]) \n",
        "                pred_dist = torch.zeros(1, coord.shape[1], coord.shape[1]) \n",
        "\n",
        "                Y = Y.cuda()\n",
        "                X = X.cuda()\n",
        "                pred_dist = pred_dist.cuda()\n",
        "\n",
        "                for p in range (0,int(coord.shape[1])):\n",
        "                    for q in range (0, p):\n",
        "                        X[p,q] = torch.linalg.norm(coord[0,p,:] -  coord[0,q,:])\n",
        "\n",
        "                pred_dist[0] = X + X.T - torch.diag(torch.diag(X))\n",
        "                pred_dist.detach_()\n",
        "                val_loss = L(pred_dist, Y) + alpha*(1 - ssim_module(pred_dist.unsqueeze(0), Y.unsqueeze(0)))\n",
        "\n",
        "                del nodes, edges, mask, nodes_new, edges_new, coord, X, Y, pred_dist\n",
        "                #torch.cuda.empty_cache()\n",
        "                #gc.collect()\n",
        "                #torch.no_grad()\n",
        "                \n",
        "            \n",
        "            if i % 1 == 0 and j % 10 == 0:\n",
        "                 print('epoch: %d,  batch: %d,  total loss: %.3f,  val loss: %.3f' % ( i, j, loss.item()/batch_size, val_loss.item()))\n",
        "                 print('MAE: %.3f,  SSIM: %.3f' % ( loss1, 1-loss2))\n",
        "                 torch.save(model.state_dict(), \"/content/model.pt\")\n",
        "                 print('model saved!')\n",
        "                 #if j % 5 == 0:\n",
        "                   #files.download(\"/content/model.pt\")\n",
        "                   #print(\"downloading model trained at epoch: %d, batch: %d \" %(i, j))\n",
        "\n",
        "\n",
        "            start = time.time()\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        \n",
        "        scheduler.step()\n",
        "\n",
        "            #print(\"ELAPSED TIME to UPDATE WEIGHTS: \", time.time() - start)\n",
        "            #if i % 1 == 0 and j %  == 0:\n",
        "                \n",
        "    \n",
        "        counter = 0\n",
        "\n",
        "        #del nodes, edges, mask, nodes_new, edges_new, coord, X, Y, pred_dist\n",
        "        #torch.cuda.empty_cache()\n",
        "        #gc.collect()\n",
        "        #torch.no_grad()\n",
        "                \n",
        "        \n",
        "        '''\n",
        "        #save the model:\n",
        "        # model_name = '[model_type]_[data_type]'\n",
        "        save_checkpoint(\n",
        "        save_dir='/content/',\n",
        "        state={\n",
        "            'model': model, \n",
        "            'name': \"GTandprojector\",\n",
        "            'epoch': i + 1,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'seed': SEED,\n",
        "            'loss': loss\n",
        "    \n",
        "            }\n",
        "        )\n",
        "        '''\n",
        "\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pSIRW5JCydF"
      },
      "outputs": [],
      "source": [
        "from matplotlib.pyplot import imshow\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "dir = '/content/drive/MyDrive/DISTANCES/'\n",
        "lst = os.listdir(dir)\n",
        "edge_len = 4 #it is 4 when we include cost maps\n",
        "\n",
        "dir_dataset = './data/'\n",
        "\n",
        "projector3D = Net()\n",
        "GT.cuda()\n",
        "projector3D.cuda()\n",
        "model = nn.Sequential(GT, projector3D)\n",
        "model.cuda()\n",
        "\n",
        "L = nn.L1Loss()\n",
        "\n",
        "if os.path.isfile('/content/model.pt'):\n",
        "    print('loading model...')\n",
        "    model.load_state_dict(torch.load(\"/content/model.pt\"))\n",
        "\n",
        "\n",
        "all_feat_paths = [dir_dataset + '/deepcov/features/', dir_dataset + '/psicov/features/', dir_dataset + '/cameo/features/']\n",
        "all_dist_paths = [dir_dataset + '/deepcov/distance/', dir_dataset + '/psicov/distance/', dir_dataset + '/cameo/distance/']\n",
        "\n",
        "total_loss = []\n",
        "coordinates_array = []\n",
        "protein_length = []\n",
        "similarity = []\n",
        "\n",
        "counter = 0\n",
        "lsttest = lst[3000:3150]\n",
        "\n",
        "for filename in lsttest:\n",
        "    filename = os.path.splitext(filename)[0]\n",
        "    filename = filename[:-3]\n",
        "\n",
        "    nodes = []\n",
        "    edges = []\n",
        "    mask = []\n",
        "    coord = []\n",
        "    nodes_out = []\n",
        "    \n",
        "    nodes, edges, mask, l = get_nodes_and_edges(filename, all_feat_paths, node_n, edge_n)\n",
        "\n",
        "    nodes = nodes.cuda()\n",
        "    edges = edges.cuda()\n",
        "    mask = mask.cuda()\n",
        "    \n",
        "    '''\n",
        "    if counter < 5:\n",
        "      print(nodes)\n",
        "    '''\n",
        "\n",
        "    nodes_new, edges = GT(nodes, edges, mask = mask)\n",
        "    nodes_new = nodes_new.cuda()\n",
        "    coord = projector3D(nodes_new, nodes)\n",
        "\n",
        "    \n",
        "    '''\n",
        "    if counter < 5:\n",
        "      print('Output Nodes:')\n",
        "      print(nodes_new)\n",
        "      print('---')\n",
        "      counter += 1\n",
        "    '''\n",
        "    coord = coord.detach_()\n",
        "\n",
        "    or_dist = edges[:,:,:,edge_len]\n",
        "\n",
        "    pred_dist = torch.zeros(1, coord.shape[1], coord.shape[1])\n",
        "    #pred_dist = np.zeros([coord.shape[1], coord.shape[1]]) \n",
        "\n",
        "\n",
        "    for p in range (0,int(coord.shape[1])):\n",
        "      for q in range (0,p):\n",
        "        pred_dist[0, p,q] = torch.linalg.norm(coord[0,p,:] -  coord[0,q,:])\n",
        "\n",
        "  \n",
        "    pred_dist[0] = pred_dist[0] + pred_dist[0].T - torch.diag(torch.diag(pred_dist[0]))\n",
        "\n",
        "    \n",
        "    or_dist = or_dist.cuda()\n",
        "    pred_dist = pred_dist.cuda()\n",
        "\n",
        "    #print(coord)\n",
        "\n",
        "    loss = L(pred_dist, or_dist)\n",
        "\n",
        "    img = or_dist.cpu().detach().numpy()[0][0]\n",
        "    ssimerror = ssim(pred_dist.cpu().detach().numpy()[0][0], img, data_range=img.max() - img.min())\n",
        "    \n",
        "    a = loss.cpu().detach().numpy()\n",
        "    \n",
        "\n",
        "    total_loss = np.append(total_loss, a)\n",
        "    \n",
        "    \n",
        "    print(np.asscalar(a))\n",
        "    #print(counter)\n",
        "    #counter += 1\n",
        "\n",
        "    \n",
        "    if np.asscalar(a) < 3.7  and counter < 8:\n",
        "        print(\"MAE:  \", np.asscalar(a))\n",
        "        print(\"SSIM: \", ssimerror)\n",
        "        print(filename)\n",
        "        print('****')\n",
        "        #print(pred_dist[0])\n",
        "        plt.figure()\n",
        "        b = pred_dist.cpu().detach().numpy()\n",
        "        imshow(np.asarray(b[0]), cmap = \"plasma\")    \n",
        "  \n",
        "\n",
        "        plt.figure()\n",
        "        b = or_dist.cpu().detach().numpy()\n",
        "        imshow(np.asarray(b[0]), cmap = \"plasma\")\n",
        "\n",
        "        counter = counter + 1\n",
        "\n",
        "        coordinates_array = np.append(coordinates_array, np.asarray(coord.cpu().detach().numpy()))\n",
        "        protein_length = np.append(protein_length, int(coord.shape[1]))\n",
        "\n",
        "    similarity = np.append(similarity, ssimerror)\n",
        "    #print(similarity)\n",
        "\n",
        "    \n",
        "    del nodes, edges, mask, coord, or_dist, pred_dist\n",
        "    gc.collect()\n",
        "\n",
        "print(similarity)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4U6JZQRGsgnm"
      },
      "outputs": [],
      "source": [
        "np.save('coordinates.npy', coordinates_array)\n",
        "np.save('length.npy', protein_length)\n",
        "np.save('loss.npy', total_loss)\n",
        "np.save('similarity.npy', similarity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-35Vu1mekue"
      },
      "outputs": [],
      "source": [
        "index = np.argmin(total_loss)\n",
        "lsttest = lst[3000:3150]\n",
        "#index = np.argmax(similarity)\n",
        "#lsttest = lst[3000:3150]\n",
        "lsttest = lsttest[index]\n",
        "counter = 0\n",
        "\n",
        "lsttest = '1zv1A-cb.npy'\n",
        "\n",
        "while counter < 1:\n",
        "    counter += 1\n",
        "    filename = os.path.splitext(lsttest)[0]\n",
        "    filename = filename[:-3]\n",
        "\n",
        "    print(filename)\n",
        "\n",
        "    nodes = []\n",
        "    edges = []\n",
        "    mask = []\n",
        "    coord = []\n",
        "    nodes_out = []\n",
        "    \n",
        "    nodes, edges, mask, l = get_nodes_and_edges(filename, all_feat_paths, node_n, edge_n)\n",
        "\n",
        "    nodes = nodes.cuda()\n",
        "    edges = edges.cuda()\n",
        "    mask = mask.cuda()\n",
        "\n",
        "\n",
        "    nodes_new, edges = GT(nodes, edges, mask = mask)\n",
        "    nodes_new = nodes_new.cuda()\n",
        "    coord = projector3D(nodes_new, nodes)\n",
        "\n",
        "\n",
        "    coord = coord.detach_()\n",
        "\n",
        "    or_dist = edges[:,:,:,edge_len]\n",
        "\n",
        "\n",
        "    pred_dist = torch.zeros(1, coord.shape[1], coord.shape[1])\n",
        "    #pred_dist = np.zeros([coord.shape[1], coord.shape[1]]) \n",
        "\n",
        "\n",
        "    for p in range (0,int(coord.shape[1])):\n",
        "      for q in range (0,p):\n",
        "        pred_dist[0, p,q] = torch.linalg.norm(coord[0,p,:] -  coord[0,q,:])\n",
        "\n",
        "  \n",
        "    pred_dist[0] = pred_dist[0] + pred_dist[0].T - torch.diag(torch.diag(pred_dist[0]))\n",
        "\n",
        "    \n",
        "    or_dist = or_dist.cuda()\n",
        "    pred_dist = pred_dist.cuda()\n",
        "\n",
        "    #print(coord)\n",
        "\n",
        "    loss = L(pred_dist, or_dist)\n",
        "    a = loss.cpu().detach().numpy()\n",
        "\n",
        "    img = or_dist.cpu().detach().numpy()[0][0]\n",
        "    ssimerror = ssim(pred_dist.cpu().detach().numpy()[0][0], img, data_range=img.max() - img.min())\n",
        "    \n",
        "    print(np.asscalar(a))\n",
        "    print(ssimerror)\n",
        "    print()\n",
        "    plt.figure()\n",
        "    b = pred_dist.cpu().detach().numpy()\n",
        "    imshow(np.asarray(b[0]))    \n",
        "  \n",
        "\n",
        "    plt.figure()\n",
        "    b = or_dist.cpu().detach().numpy()\n",
        "    imshow(np.asarray(b[0]))\n",
        "\n",
        "np.save('coordinates' + str(filename) + '_nocost.npy', coord.cpu().detach().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lcLfqvendJtt"
      },
      "outputs": [],
      "source": [
        "print(np.max(total_loss))\n",
        "print(np.mean(total_loss))\n",
        "print(np.min(total_loss))\n",
        "print(np.std(total_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUUasvi5e6HU"
      },
      "outputs": [],
      "source": [
        "print(np.max(similarity))\n",
        "print(np.mean(similarity))\n",
        "print(np.min(similarity))\n",
        "print(np.std(similarity))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tessTx1UvayJ"
      },
      "outputs": [],
      "source": [
        "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "pytorch_total_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgBtpR2L10_q"
      },
      "outputs": [],
      "source": [
        "pytorch_total_params = sum(p.numel() for p in GT.parameters())\n",
        "pytorch_total_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQrfu8sD14tM"
      },
      "outputs": [],
      "source": [
        "pytorch_total_params = sum(p.numel() for p in projector3D.parameters())\n",
        "pytorch_total_params"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Graph Transformer.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}